{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/skihikingkevin/magic-feature-v2-krzy-new-idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig =  pd.read_csv('./input/train.csv', header=0)\n",
    "test_orig =  pd.read_csv('./input/test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2750086, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques = pd.concat([train_orig[['question1', 'question2']], \\\n",
    "        test_orig[['question1', 'question2']]], axis=0).reset_index(drop='index')\n",
    "ques.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "def word_match_share(q1, q2, stops=None):\n",
    "    q1 = str(q1).lower().split()\n",
    "    q2 = str(q2).lower().split()\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in q1:\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in q2:\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0.\n",
    "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
    "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
    "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_dict = defaultdict(dict)\n",
    "for i in range(ques.shape[0]):\n",
    "        wm = word_match_share(ques.question1[i], ques.question2[i], stops=stops)\n",
    "        q_dict[ques.question1[i]][ques.question2[i]] = wm\n",
    "        q_dict[ques.question2[i]][ques.question1[i]] = wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(q_dict, open('./models/weighted_intersect.pkl', 'wb'))\n",
    "#q_dict = pickle.load( open('./models/weighted_intersect.pkl', 'rb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def q1_q2_intersect(row):\n",
    "    return(len(set(q_dict[row['question1']]).intersection(set(q_dict[row['question2']]))))\n",
    "\n",
    "def q1_q2_wm_ratio(row):\n",
    "    q1 = q_dict[row['question1']]\n",
    "    q2 = q_dict[row['question2']]\n",
    "    inter_keys = set(q1.keys()).intersection(set(q2.keys()))\n",
    "    if(len(inter_keys) == 0): return 0.\n",
    "    inter_wm = 0.\n",
    "    total_wm = 0.\n",
    "    for q,wm in q1.items():\n",
    "        if q in inter_keys:\n",
    "            inter_wm += wm\n",
    "        total_wm += wm\n",
    "    for q,wm in q2.items():\n",
    "        if q in inter_keys:\n",
    "            inter_wm += wm\n",
    "        total_wm += wm\n",
    "    if(total_wm == 0.): return 0.\n",
    "    return inter_wm/total_wm\n",
    "\n",
    "train_orig['q1_q2_wm_ratio'] = train_orig.apply(q1_q2_wm_ratio, axis=1, raw=True)\n",
    "train_orig['q1_q2_intersect'] = train_orig.apply(q1_q2_intersect, axis=1, raw=True)\n",
    "\n",
    "train_feat = train_orig[['q1_q2_intersect', 'q1_q2_wm_ratio']]\n",
    "train_feat.to_csv('./datasets/weighted_intersec_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_orig['q1_q2_wm_ratio'] = test_orig.apply(q1_q2_wm_ratio, axis=1, raw=True)\n",
    "test_orig['q1_q2_intersect'] = test_orig.apply(q1_q2_intersect, axis=1, raw=True)\n",
    "M\n",
    "test_feat = test_orig[['q1_q2_intersect', 'q1_q2_wm_ratio']]\n",
    "train_feat.to_csv('./datasets/weighted_intersec_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
