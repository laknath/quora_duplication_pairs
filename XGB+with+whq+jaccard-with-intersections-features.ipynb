{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/dasolmar/xgb-with-whq-jaccard/code/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "import operator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import plot, show, subplot, specgram, imshow, savefig\n",
    "\n",
    "RS = 12357\n",
    "ROUNDS = 450\n",
    "x_train_size = (404290, 6)\n",
    "x_test_size = (2345796, 3)\n",
    "\n",
    "print(\"Started\")\n",
    "np.random.seed(RS)\n",
    "input_folder = './input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data: X_train: (404290, 6), X_test: (2345796, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(input_folder + 'train.csv')\n",
    "df_test  = pd.read_csv(input_folder + 'test.csv')\n",
    "\n",
    "print(\"Original data: X_train: {}, X_test: {}\".format(df_train.shape, df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "def count_duplicates(row):\n",
    "    counter[row['question1']] += 1\n",
    "    counter[row['question2']] += 1\n",
    "    \n",
    "df_train.apply(count_duplicates, axis=1, raw=True)\n",
    "df_test.apply(count_duplicates, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_q1_freq = df_train['question1'].map(counter)\n",
    "train_q2_freq = df_train['question2'].map(counter)\n",
    "\n",
    "test_q1_freq = df_test['question1'].map(counter)\n",
    "test_q2_freq = df_test['question2'].map(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def create_feature_map(features):\n",
    "\toutfile = open('xgb.fmap', 'w')\n",
    "\ti = 0\n",
    "\tfor feat in features:\n",
    "\t\toutfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "\t\ti = i + 1\n",
    "\toutfile.close()\n",
    "\n",
    "def add_word_count(x, df, word):\n",
    "\tx['q1_' + word] = df['question1'].apply(lambda x: (word in str(x).lower())*1)\n",
    "\tx['q2_' + word] = df['question2'].apply(lambda x: (word in str(x).lower())*1)\n",
    "\tx[word + '_both'] = x['q1_' + word] * x['q2_' + word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          None\n",
       "1          None\n",
       "2          None\n",
       "3          None\n",
       "4          None\n",
       "5          None\n",
       "6          None\n",
       "7          None\n",
       "8          None\n",
       "9          None\n",
       "10         None\n",
       "11         None\n",
       "12         None\n",
       "13         None\n",
       "14         None\n",
       "15         None\n",
       "16         None\n",
       "17         None\n",
       "18         None\n",
       "19         None\n",
       "20         None\n",
       "21         None\n",
       "22         None\n",
       "23         None\n",
       "24         None\n",
       "25         None\n",
       "26         None\n",
       "27         None\n",
       "28         None\n",
       "29         None\n",
       "           ... \n",
       "2345766    None\n",
       "2345767    None\n",
       "2345768    None\n",
       "2345769    None\n",
       "2345770    None\n",
       "2345771    None\n",
       "2345772    None\n",
       "2345773    None\n",
       "2345774    None\n",
       "2345775    None\n",
       "2345776    None\n",
       "2345777    None\n",
       "2345778    None\n",
       "2345779    None\n",
       "2345780    None\n",
       "2345781    None\n",
       "2345782    None\n",
       "2345783    None\n",
       "2345784    None\n",
       "2345785    None\n",
       "2345786    None\n",
       "2345787    None\n",
       "2345788    None\n",
       "2345789    None\n",
       "2345790    None\n",
       "2345791    None\n",
       "2345792    None\n",
       "2345793    None\n",
       "2345794    None\n",
       "2345795    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build question intersection map\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "q_dict = defaultdict(set)\n",
    "\n",
    "def build_intersects(row):\n",
    "    q_dict[row['question1']].add(row['question2'])\n",
    "    q_dict[row['question2']].add(row['question1'])\n",
    "    \n",
    "def count_intersect(row):\n",
    "    return(len(q_dict[row['question1']].intersection(q_dict[row['question2']])))\n",
    "\n",
    "df_train.apply(build_intersects, axis=1, raw=True)\n",
    "df_test.apply(build_intersects, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(q_dict, open('./datasets/q_intersect_dict.pkl', 'wb'))\n",
    "#q_dict = pickle.load( open('./datasets/q_intersect_dict.pkl', 'rb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_intersects = df_train.apply(count_intersect, axis=1, raw=True)\n",
    "#test_intersects = df_test.apply(count_intersect, axis=1, raw=True)\n",
    "\n",
    "#train_intersects.to_csv('./datasets/train_intersects.csv')\n",
    "#test_intersects.to_csv('./datasets/test_intersects.csv')\n",
    "\n",
    "train_intersects = pd.DataFrame.from_csv('./datasets/train_intersects.csv', header = -1)\n",
    "test_intersects = pd.DataFrame.from_csv('./datasets/test_intersects.csv', header = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "temp = train_intersects.value_counts()\n",
    "sns.barplot(temp.index[:20], temp.values[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count level 2 intersected statements\n",
    "\n",
    "def count_intersect_l2(row):\n",
    "    q1_l2 = set([q1 for q in q_dict[row['question1']] for q1 in q_dict[q]]) | q_dict[row['question1']]\n",
    "    q2_l2 = set([q2 for q in q_dict[row['question2']] for q2 in q_dict[q]]) | q_dict[row['question2']]\n",
    "    \n",
    "    return(len(q1_l2.intersection(q2_l2)))\n",
    "\n",
    "train_intersects_l2 =  df_train.apply(count_intersect_l2, axis=1, raw=True)\n",
    "test_intersects_l2 = df_test.apply(count_intersect_l2, axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_intersects_l2.to_csv('./datasets/train_intersects_l2.csv')\n",
    "#test_intersects_l2.to_csv('./datasets/test_intersects_l2.csv')\n",
    "\n",
    "train_intersects_l2 = pd.DataFrame.from_csv('./datasets/train_intersects_l2.csv', header = -1)\n",
    "test_intersects_l2 = pd.DataFrame.from_csv('./datasets/test_intersects_l2.csv', header = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "temp = train_intersects_l2.value_counts()\n",
    "sns.barplot(temp.index[:20], temp.values[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If a word appears only once, we ignore it completely (likely a typo)\n",
    "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "\treturn 0 if count < min_count else 1 / (count + eps)\n",
    "\n",
    "def word_shares(row):\n",
    "\tq1_list = str(row['question1']).lower().split()\n",
    "\tq1 = set(q1_list)\n",
    "\tq1words = q1.difference(stops)\n",
    "\tif len(q1words) == 0:\n",
    "\t\treturn '0:0:0:0:0:0:0:0'\n",
    "        \n",
    "\tq2_list = str(row['question2']).lower().split()\n",
    "\tq2 = set(q2_list)\n",
    "\tq2words = q2.difference(stops)\n",
    "\tif len(q2words) == 0:\n",
    "\t\treturn '0:0:0:0:0:0:0:0'\n",
    "\n",
    "\twords_hamming = sum(1 for i in zip(q1_list, q2_list) if i[0]==i[1])/max(len(q1_list), len(q2_list))\n",
    "\n",
    "\tq1stops = q1.intersection(stops)\n",
    "\tq2stops = q2.intersection(stops)\n",
    "\n",
    "\tq1_2gram = set([i for i in zip(q1_list, q1_list[1:])])\n",
    "\tq2_2gram = set([i for i in zip(q2_list, q2_list[1:])])\n",
    "\n",
    "\tshared_2gram = q1_2gram.intersection(q2_2gram)\n",
    "\n",
    "\tshared_words = q1words.intersection(q2words)\n",
    "\tshared_weights = [weights.get(w, 0) for w in shared_words]\n",
    "\tq1_weights = [weights.get(w, 0) for w in q1words]\n",
    "\tq2_weights = [weights.get(w, 0) for w in q2words]\n",
    "\ttotal_weights = q1_weights + q1_weights\n",
    "\t\t\n",
    "\tR1 = np.sum(shared_weights) / np.sum(total_weights) #tfidf share\n",
    "\tR2 = len(shared_words) / (len(q1words) + len(q2words) - len(shared_words)) #count share\n",
    "\tR31 = len(q1stops) / len(q1words) #stops in q1\n",
    "\tR32 = len(q2stops) / len(q2words) #stops in q2\n",
    "\tRcosine_denominator = (np.sqrt(np.dot(q1_weights,q1_weights))*np.sqrt(np.dot(q2_weights,q2_weights)))\n",
    "\tRcosine = np.dot(shared_weights, shared_weights)/Rcosine_denominator\n",
    "\tif len(q1_2gram) + len(q2_2gram) == 0:\n",
    "\t\tR2gram = 0\n",
    "\telse:\n",
    "\t\tR2gram = len(shared_2gram) / (len(q1_2gram) + len(q2_2gram))\n",
    "\treturn '{}:{}:{}:{}:{}:{}:{}:{}'.format(R1, R2, len(shared_words), R31, R32, R2gram, Rcosine, words_hamming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_qs = pd.Series(df_train['question1'].tolist() + df_train['question2'].tolist()).astype(str)\n",
    "words = (\" \".join(train_qs)).lower().split()\n",
    "counts = Counter(words)\n",
    "weights = {word: get_weight(count) for word, count in counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.concat([df_train, df_test])\n",
    "#df['word_shares'] = df.apply(word_shares, axis=1, raw=True)\n",
    "df = pd.read_csv('./datasets/why_jaccard_features.csv')\n",
    "#df.to_csv('./datasets/why_jaccard_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Features processing, be patient...\")\n",
    "    \n",
    "    x = pd.DataFrame()\n",
    "\n",
    "    print('word match')\n",
    "    x['word_match']       = df['word_shares'].apply(lambda x: float(x.split(':')[0]))\n",
    "    x['word_match_2root'] = np.sqrt(x['word_match'])\n",
    "    x['tfidf_word_match'] = df['word_shares'].apply(lambda x: float(x.split(':')[1]))\n",
    "    x['shared_count']     = df['word_shares'].apply(lambda x: float(x.split(':')[2]))\n",
    "\n",
    "    print('stops1 ratio')\n",
    "    x['stops1_ratio']     = df['word_shares'].apply(lambda x: float(x.split(':')[3]))\n",
    "    x['stops2_ratio']     = df['word_shares'].apply(lambda x: float(x.split(':')[4]))\n",
    "    x['shared_2gram']     = df['word_shares'].apply(lambda x: float(x.split(':')[5]))\n",
    "    x['cosine']           = df['word_shares'].apply(lambda x: float(x.split(':')[6]))\n",
    "    x['words_hamming']    = df['word_shares'].apply(lambda x: float(x.split(':')[7]))\n",
    "    x['diff_stops_r']     = x['stops1_ratio'] - x['stops2_ratio']\n",
    "\n",
    "    print('lengths')\n",
    "    x['len_q1'] = df['question1'].apply(lambda x: len(str(x)))\n",
    "    x['len_q2'] = df['question2'].apply(lambda x: len(str(x)))\n",
    "    x['diff_len'] = x['len_q1'] - x['len_q2']\n",
    "\n",
    "    print('cap counts')\n",
    "    x['caps_count_q1'] = df['question1'].apply(lambda x:sum(1 for i in str(x) if i.isupper()))\n",
    "    x['caps_count_q2'] = df['question2'].apply(lambda x:sum(1 for i in str(x) if i.isupper()))\n",
    "    x['diff_caps'] = x['caps_count_q1'] - x['caps_count_q2']\n",
    "\n",
    "    print('len chart')\n",
    "    x['len_char_q1'] = df['question1'].apply(lambda x: len(str(x).replace(' ', '')))\n",
    "    x['len_char_q2'] = df['question2'].apply(lambda x: len(str(x).replace(' ', '')))\n",
    "    x['diff_len_char'] = x['len_char_q1'] - x['len_char_q2']\n",
    "\n",
    "    print('len word')\n",
    "    x['len_word_q1'] = df['question1'].apply(lambda x: len(str(x).split()))\n",
    "    x['len_word_q2'] = df['question2'].apply(lambda x: len(str(x).split()))\n",
    "    x['diff_len_word'] = x['len_word_q1'] - x['len_word_q2']\n",
    "\n",
    "    print('avg word len')\n",
    "    x['avg_world_len1'] = x['len_char_q1'] / x['len_word_q1']\n",
    "    x['avg_world_len2'] = x['len_char_q2'] / x['len_word_q2']\n",
    "    x['diff_avg_word'] = x['avg_world_len1'] - x['avg_world_len2']\n",
    "    \n",
    "    print('exact same')\n",
    "    x['exactly_same'] = (df['question1'] == df['question2']).astype(int)\n",
    "    x['duplicated'] = df.duplicated(['question1','question2']).astype(int)\n",
    "    add_word_count(x, df,'how')\n",
    "    add_word_count(x, df,'what')\n",
    "    add_word_count(x, df,'which')\n",
    "    add_word_count(x, df,'who')\n",
    "    add_word_count(x, df,'where')\n",
    "    add_word_count(x, df,'when')\n",
    "    add_word_count(x, df,'why')\n",
    "    print('features done...')\n",
    "    \n",
    "    print(x.columns)\n",
    "    #print(x.describe())\n",
    "\n",
    "    print(\"Saving processed list...\")\n",
    "    x.to_csv('./datasets/why_jaccard_features_processed.csv')\n",
    "    \n",
    "    feature_names = list(x.columns.values)\n",
    "    create_feature_map(feature_names)\n",
    "    print(\"Features: {}\".format(feature_names))\n",
    "    \n",
    "    #x_train = x[:df_train.shape[0]]\n",
    "    #x_test  = x[df_train.shape[0]:]\n",
    "    #y_train = df_train['is_duplicate'].values\n",
    "    #del x, df_train\n",
    "    #return x_train, x_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = pd.read_csv('./datasets/why_jaccard_features_processed.csv', header=0)\n",
    "\n",
    "x['q1_freq'] = train_q1_freq.tolist() + test_q1_freq.tolist()\n",
    "x['q2_freq'] = train_q2_freq.tolist() + test_q2_freq.tolist()\n",
    "\n",
    "#x_train = x[:x_train_size[0]]\n",
    "#x_test  = x[x_train_size[0]:]\n",
    "#y_train = df_train['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = list(x.columns.values)\n",
    "create_feature_map(feature_names)\n",
    "print(\"Features: {}\".format(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_test[x_test['q1_freq'].isnull()].head()\n",
    "#x_test['q1_freq'].tail()\n",
    "#x_train['q1_freq'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train.to_csv('./datasets/why_jaccard_x_train.csv')\n",
    "x_test.to_csv('./datasets/why_jaccard_x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('./datasets/why_jaccard_x_train.csv')\n",
    "x_test = pd.read_csv('./datasets/why_jaccard_x_test.csv')\n",
    "y_train = df_train['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train['q_intersect'] = train_intersects\n",
    "x_test['q_intersect'] = test_intersects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x, df_train, train_q1_freq, test_q1_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "-----------------\n",
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1: # Now we oversample the negative class - on your own risk of overfitting!\n",
    "\tpos_train = x_train[y_train == 1]\n",
    "\tneg_train = x_train[y_train == 0]\n",
    "\n",
    "\tprint(\"Oversampling started for proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\tp = 0.165\n",
    "\tscale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
    "\twhile scale > 1:\n",
    "\t\tneg_train = pd.concat([neg_train, neg_train])\n",
    "\t\tscale -=1\n",
    "\tneg_train = pd.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
    "\tprint(\"Oversampling done, new proportion: {}\".format(len(pos_train) / (len(pos_train) + len(neg_train))))\n",
    "\n",
    "\tx_train = pd.concat([pos_train, neg_train])\n",
    "\ty_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
    "\tdel pos_train, neg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_xgb(x_train, x_val, y_train, y_val, params):\n",
    "\tprint(\"Will train XGB for {} rounds, RandomSeed: {}\".format(ROUNDS, RS))\n",
    "\n",
    "\txg_train = xgb.DMatrix(x_train, label=y_train)\n",
    "\txg_val = xgb.DMatrix(x_val, label=y_val)\n",
    "\n",
    "\twatchlist  = [(xg_train,'train'), (xg_val,'eval')]\n",
    "\treturn xgb.train(params, xg_train, ROUNDS, watchlist), xg_train, xg_val\n",
    "\n",
    "def predict_xgb(bst, x_test):\n",
    "\treturn bst.predict(xgb.DMatrix(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.05, random_state=RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.11\n",
    "params['max_depth'] = 5\n",
    "params['silent'] = 1\n",
    "params['seed'] = RS\n",
    "\n",
    "print(\"Training data: X_train: {}, Y_train: {}, X_test: {}\".format(x_train.shape, len(y_train), x_test.shape))\n",
    "bst, xg_train, xg_val = train_xgb(x_train, x_valid, y_train, y_valid, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_train = bst.predict(xg_train)\n",
    "p_val = bst.predict(xg_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_prec = sum((p_val > 0.5) == y_valid)/len(y_valid)\n",
    "train_prec = sum((p_train > 0.5) == y_train)/len(p_train)\n",
    "\n",
    "print(\"Training accuracy: {}, Validation accuracy: {}\".format(train_prec, val_prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#pickle.dump(bst, open('./models/models_intersect_' + str(ROUNDS) + '.pkl', 'wb'))\n",
    "bst = pickle.load( open('./models/models_intersect_' + str(ROUNDS) + '.pkl', 'rb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"predicting...\")\n",
    "preds = predict_xgb(bst, x_test)\n",
    "\n",
    "print(\"Writing output...\")\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = df_test['test_id']\n",
    "sub['is_duplicate'] = preds\n",
    "sub.to_csv(\"xgb_seed{}_intersect_n{}.csv\".format(RS, ROUNDS), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print(\"Features importances...\")\n",
    "importance = bst.get_fscore()\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "ft = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "print(importance)\n",
    "\n",
    "ft.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 25))\n",
    "plt.gcf().savefig('features_importance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logloss\n",
    "\n",
    "#### Iteration 200\n",
    "\n",
    "* With freq ~ XGB depth 9 - train-error:0.099994\teval-error:0.109187 | Training accuracy: 0.9000060058857681, Validation accuracy: 0.9108810198753984 | **0.22 on LB**\n",
    "\n",
    "#### Iteration 315\n",
    " \n",
    "* With freq - [314]\ttrain-logloss:0.239994\teval-logloss:0.246721 **(0.21956 on LB)**\n",
    "* Without freq - [314]\ttrain-logloss:0.312187\teval-logloss:0.319391\n",
    "\n",
    "#### iteration 350\n",
    "\n",
    "* With intersect - [349]\ttrain-logloss:0.187006\teval-logloss:0.194715 | Training accuracy: 0.921968923517218, Validation accuracy: 0.9198718770019219 **(0.17036 on LB)**\n",
    "* With freq - [349]\ttrain-logloss:0.238551\teval-logloss:0.245807 **(0.21543 on LB)**\n",
    "\n",
    "#### iteration 380\n",
    "\n",
    "* With freq - [379]\ttrain-logloss:0.237033\teval-logloss:0.244844 **(0.21524 on LB)**\n",
    "* With 0.05 split - [379]\ttrain-logloss:0.238077\teval-logloss:0.246341\n",
    "* [379]\ttrain-logloss:0.235721\teval-logloss:0.246734 | Training accuracy: 0.895017116774439, Validation accuracy: 0.9108810198753984\n",
    "\n",
    "#### iteration 400\n",
    "\n",
    "* jaccard features + freq - [399]\ttrain-error:0.086034\teval-error:0.102852 | Training accuracy: 0.9139656863726452, Validation accuracy: 0.9108810198753984\n",
    "\n",
    "#### iteration 450\n",
    "* Training accuracy: 0.9232420855581076, Validation accuracy: 0.9205637411915438 **LB 0.16956**\n",
    "* [449]\ttrain-error:0.086919\teval-error:0.101089 | Training accuracy: 0.9130810656258387, Validation accuracy: 0.8989109545163357 **LB: 0.22403**\n",
    "\n",
    "#### iteration 800\n",
    "* With freq - [799]\ttrain-logloss:0.223248\teval-logloss:0.237988 **(0.21861 on LB)**\n",
    "In [13]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
